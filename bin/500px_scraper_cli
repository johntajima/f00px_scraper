#!/usr/bin/env ruby

$:.unshift File.dirname(__FILE__)

require 'thor'
require 'csv'
require './lib/f00px_scraper'

class ScraperCLI < Thor

  desc "csv", "export list of photographers from FEATURE list to csv file"
  option :key, required: true, :aliases => :k
  option :feature, :aliases => :f, :enum => F00pxScraper::FEATURES
  option :per_page, type: :numeric, :aliases => :l
  option :start_page, type: :numeric, :aliases => :s
  option :end_page, type: :numeric, :aliases => :e
  def csv()
    params = {
      consumer_key: options[:key], 
      feature: options[:feature] || F00pxScraper::DEFAULT_FEATURE,
      per_page: options[:per_page] || 100,
      start_page: options[:start_page] || 1,
      end_page: options[:end_page] || 1
    }

    F00pxScraper.to_csv(params)
  end


  desc "twitter FILENAME.csv", "export twitter handles from a CSV file"
  def twitter(file)
    list = extract_twitter_from_csv(file)
    output = File.basename(file, ".*")
    File.open("#{output}.txt", 'wb') do |f|
      f.write list.join("\n")
    end
  end

  desc "new_twitter FILENAME.csv", "export list of new twitter handles that are not followed"
  def new_twitter(file)
    list = extract_twitter_from_csv(file)
    existing = `t followings`.split
    new_list = list - existing

    output = File.basename(file, ".*")
    File.open("#{output}_new.txt", 'wb') do |f|
      f.write new_list.join("\n")
    end
  end

  private

  def extract_twitter_from_csv(file)
    list = []
    CSV.foreach(file, :headers => true) do |row|
      list << row['twitter']
    end
    list.uniq.reject {|x| x.length == 0 }
  end
end


ScraperCLI.start(ARGV)
